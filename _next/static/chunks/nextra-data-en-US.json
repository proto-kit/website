{"/docs/library/math":{"title":"Math","data":{"":"Generally, all types that are usable in o1js are also usable out-of-the-box in protokit.\nBut there are some caveats to dealing with bounded integers (UInt64, UInt32).","integers#Integers":"By default, o1js exposes two classes UInt64 and UInt32 to protect you from overflows that can happen\nif you use Field directly.\nUnfortunately, these don't work well with Protokit since they use the hard-failing o1js assertions instead of the protokit-specific assert.\nThis leads to your application being non-complete and being unable to include failed transactions in settlements.To overcome this, we created a number of classes in @proto-kit/library that handle all of that for you while providing the same interface as the vanilla variants.\nUInt32\nUInt64\nUInt112\nUInt224\nIn addition to the methods known from o1js, we implement the sqrtMod() and sqrtFloor() functions to help facilitate square-root calculations.\nMake sure to import from @proto-kit/library when using UInt32 and UInt64","creating-protokit-uints#Creating protokit UInts":"There are multiple ways of creating UInts, each of them with their own properties.\nThis example uses UInt64, but can be used with any other UInt the same way.The most straight forward one is using UInt64.from(). This accepts UInt64 | string | bigint | number.\nIt should be used for creation of a constant or for copying a existing UInt.\nTo convert a Field into a UInt, you can use both the Safe and Unsafe fromField() function.\nBecause range checks (which are used under the hood to enable the safety of UInts) are very expensive,\nthese different methods of creating and transforming UInts are a way for developers to optimize and decrease proving effort.","transforming-uints#Transforming UInts":"Sometimes we need to go from a specific UInt bit-range to a different one. Let's say we want to go from UInt32 to UInt64 and back.The upward direction is trivial and will not generate additional constraints\nGoing down to UInt32 again, we need to range-check the 64-bit number to ensure it is within 32-bits.\nTherefore, we need to use the Safe.fromField method.\nFor some UInts, simpler conversion functions exist.\nUInt32.toUInt64()\nUInt112.toUInt224()","converting-to-o1js-uint64#Converting to o1js UInt64":"Every UInt from the @proto-kit/library package also has a conversion function to turn it into a o1js UInt64"}},"/docs/provable-code":{"title":"Provable code","data":{"":"In order for a zk-rollup to verify the correctness of its operation, it has to be able to prove that e.g. the transaction was executed correctly.\nThis is possible thanks to the fact that all the underlying Protokit rollup code is written as zk-circuits using o1js. Therefore creating provable code, resulting in zk-proofs.","what-is-o1js#What is o1js?":"o1js is a library created by the team behind Mina that powers all of Protokit.\nIt is the backbone of everything we do and provides a simple abstraction over all zk-related things.\nYou can learn more about o1js in the official docs.\nSince protokit and mina are both zk-native, we have to be able to \"prove\" all of the code that we write for our application.\nProving means turning a computation into a zk-proof. That happens over multiple steps.\nWe write our business and protocol logic using Protokit. In that process we will work with the primitives that o1js exposes to developers.\nThat means types for Integers, PublicKeys, hashing functions, Conditionals, etc.\nWe execute your code and translate it behind the scenes in something that is called a \"circuit\". A circuit is arithmetic representation of your application's code.\nThis representation has to be the same for every possible execution of your code. This is why we can't have dynamically bounded loops and typescript if statements in our code (though there are some tricks to mitigate that).\nThe circuit is then used to prove our execution and create a zk-proof (a.k.a. zk-SNARK).\nThis proof can then be verified by any other party using a small \"verification key\", which is also generated using the circuit.\nSo to summarize, Protokit uses o1js to lift all the snark-related stuff for us, so we can focus on writing good applications.","programming-patterns-in-circuits#Programming patterns in circuits":"Writing provable code is relatively straightforward, but there are some things to keep in mind.\nNature of proof systems / o1js dictates that all code we execute must be static and have the exact same execution steps with every possible input.\nThis creates some caveats we have to watch out for during development, such as avoiding dynamic sized computation like dynamic loops, or \"native\" if statements.","loops#Loops":"Dynamic sized loops are not possible. However, there are some exceptions and patterns we can still use.\nSpecifically, fixed bounded loops. That means that we can create loops as long as the loop always runs the exact same amount of iterations.The first pattern can be used pretty safely:\nOne has to be a bit more careful with the second pattern though:\nThe developer has to make sure that the length of inputs stays the same for every invocation.\nA failure to do so will result in something we call \"compiler/prover discrepancies\", where the circuit we are trying to prove is a different one from the originally compiled one.\nThis will throw obscure errors way down the stack, so it's better to avoid these issues alltogether.Logically, correct usage of this pattern also enables usage of methods like forEach, map, reduce, etc."}},"/docs/reference/api/README":{"title":"@proto-kit/api","data":{"":"@proto-kit/api â€¢ DocsDocumentation / @proto-kit/api"}},"/docs/reference/cli/README":{"title":"@proto-kit/cli","data":{"":"@proto-kit/cli â€¢ DocsDocumentation / @proto-kit/cli"}},"/docs/reference/common/README":{"title":"@proto-kit/common","data":{"":"@proto-kit/common â€¢ DocsDocumentation / @proto-kit/common"}},"/docs/reference/deployment/README":{"title":"@proto-kit/deployment","data":{"":"@proto-kit/deployment â€¢ DocsDocumentation / @proto-kit/deployment","general#General":"This package provides a suite of Dockerfiles and compose files to start protokit\nin a variety of settings and modes.Everything is controlled via Environments.\nThese are basically bundles of Appchains that are configured for different roles.\nEvery environment has a name and consists of multiple Configurations.The base image built from base/Dockerfile executes any js file and passes in the environment and configuration name as arguments.Configuration happens via a .env file that specifies a few things:\nAmong those are the profiles that should executed, the DB connection string, and the entrypoints for the different images","currently-available-services#Currently available services:":"Persistance with\nPostgres (profile: db)\nRedis (profiles: db, worker)\nSequencer: SEQUENCER_CONFIG (profile: simple-sequencer)\nWorker: WORKER_CONFIG (profile: worker)\nDevelopment-base: Usage for locally built starter-kit, see starter-kit documentation","usage#Usage":"A example of how to use it with a local framework repo can be found under the package stack\nThe configuration of that setup can be found under .envExecuting it works via docker-compose up --build run in the stack package.","extentending-deployment-compose-files#Extentending deployment compose files":"Option 1: Using include and specifying a exported Environments configurationOption 2: Using extend and override the cmdBe aware that including docker-compose files preserves their relationship in terms of relational paths, while extend does not (it behaves like copying the text into the parent file)"}},"/docs/reference/indexer/README":{"title":"@proto-kit/indexer","data":{"":"@proto-kit/indexer â€¢ DocsDocumentation / @proto-kit/indexer"}},"/docs/reference/deployment/globals":{"title":"@proto-kit/deployment","data":{"":"@proto-kit/deployment â€¢ DocsDocumentation / @proto-kit/deployment"}},"/docs/reference/library/README":{"title":"@proto-kit/library","data":{"":"@proto-kit/library â€¢ DocsDocumentation / @proto-kit/library"}},"/docs/reference/module/globals":{"title":"@proto-kit/module","data":{"":"@proto-kit/module â€¢ DocsDocumentation / @proto-kit/module"}},"/docs/reference/persistance/README":{"title":"@proto-kit/persistance","data":{"":"@proto-kit/persistance â€¢ DocsDocumentation / @proto-kit/persistance"}},"/docs/reference/processor/README":{"title":"@proto-kit/processor","data":{"":"@proto-kit/processor â€¢ DocsDocumentation / @proto-kit/processor"}},"/docs/reference/protocol/README":{"title":"@proto-kit/protocol","data":{"":"@proto-kit/protocol â€¢ DocsDocumentation / @proto-kit/protocolProtocol contains to all circuit-aware data types and provers","statetransitionprover#StateTransitionProver":"The StateTransitionProver takes a list of StateTransitions, checks and proves their precondition and update to the respective merkletree represented by the state root public input.In the public input, the prover transitions from two fields:\nstate root\ntransitions hash\nThe transitions hash is the commitment to a hash list where every state transition gets appended one-by-one.The StateTransitionsProver batches the application of multiple state transitions together.\nIf the amount of state transitions if greater than the batch size, the seperate proofs can be merged together.In the end, the publicInput of the StateTransitionProof should contain the following content:\nfromTransitionsHash: 0 To prove that all STs have been applied, the transitionsHash must start at zero (i.e. a empty hash list)\ntoTransitionsHash This value must be the same as the transitionsHash in the AppChainProof to guarantee that all (and same) statetransitions that have been outputted by the AppChain have been applied\nfrom- and toStateRoot These values represent the root of the state tree and will later be stitched together to arrive at the final stateroot for a bundle","blockprover#BlockProver":"The BlockProver's responsibility is to verify and put together the AppChainProof and StateTransitionProof.\nIt verifies that the transitionsHash is the same across both proofs and then takes the new state root proved by the STProof.In the end, the BlockProof proofs that:\nthe AppChain has been executed correctly\nthe resulting state changes have been applied correctly and fully to the state root\nMultiple BlockProofs will then be merged together, signed by the sequencer and published to the base layer.","rollupmerkletree#RollupMerkleTree":"The RollupMerkleTree is a custom merkle tree implementation that supports the injection of a storage adapter.\nThe interface for that adapter can be found as the interface MerkleTreeStorage.Adapters can implement any storage backend, like In-Memory and Database, and supports a process called \"virtualization\".\nVirtualization is the process of layering different Adapters on top of each other.\nFor example if I want to simulate some transactions to a merkle tree, I can virtualize a database adapter into a MemoryAdapter.\nIf I am happy with the result, I can merge the results into the database or, if not, discard them without writing the changes to the database."}},"/docs/reference/protocol/globals":{"title":"@proto-kit/protocol","data":{"":"@proto-kit/protocol â€¢ DocsDocumentation / @proto-kit/protocol"}},"/docs/reference/sdk/globals":{"title":"@proto-kit/sdk","data":{"":"@proto-kit/sdk â€¢ DocsDocumentation / @proto-kit/sdk"}},"/docs/reference/sequencer/README":{"title":"@proto-kit/sequencer","data":{"":"@proto-kit/sequencer â€¢ DocsDocumentation / @proto-kit/sequencerThis package includes everything that is required to run a sequencer","sequencer#Sequencer":"A Sequencer is structure similar to a Runtime.\nIt is given a list of SequencerModules, that are then dynamically instantiated and resolved by the Sequencer.\nWhen calling .start() on a sequencer, the sequencer starts up all the modules and exposes the services provided by them.","sequencer-modules#Sequencer modules":"A Sequencer module is an abstract class that needs to be extended by any concrete sequencer module implementation(s).\nThe generic type parameter Config refers to the configuration object a module consumes.\nMore on that below.The start() method is called by the sequencer when it gets started.\nIt returns a Promise that has to resolve after initialization, since it will block in the sequencer startup.\nThat means that you mustn't await server.start() for example."}},"/docs/reference/sequencer/globals":{"title":"@proto-kit/sequencer","data":{"":"@proto-kit/sequencer â€¢ DocsDocumentation / @proto-kit/sequencer"}},"/docs/reference/stack/README":{"title":"@proto-kit/stack","data":{"":"@proto-kit/stack â€¢ DocsDocumentation / @proto-kit/stackdocker-compose up --buildSelect services to use in .env using profilesSee deployment README.md for more information"}},"/docs/reference/stack/globals":{"title":"@proto-kit/stack","data":{"":"@proto-kit/stack â€¢ DocsDocumentation / @proto-kit/stack"}},"/docs/sequencer/workers":{"title":"Worker Architecture","data":{"":"The way protokit is architected, in regards to computation-heavy tasks, we have the following three-party setup:\nSequencer - this is the master \"node\" that does the sequencing, tracing and pushes proving tasks. In reality, this can be a multi-process deployment, but we can simplify this to a single actor here.\nWorkers - One or more stateless actors that have a set of tasks that they can compute. Tasks in our case are mostly proving-related work.\nMessage Queue - Distributes tasks from the sequencer to the workers and reports back the results\nIf worker modules are defined in the AppChain it becomes a worker. This has the same architecture as a regular AppChain,\nbut it can process expensive asynchronous tasks, such as Block Proving. An AppChain can be defined such that only worker modules are present, which means\nits only function is to execute tasks, rather than serve as a sequencer. For testing purposes, it is fine to have the main AppChain be the worker, but in\nproduction set-ups you will likely want multiple stand-alone workers defined, separately.","localtaskworkermodule#LocalTaskWorkerModule":"This module is used to create a worker locally. Without this being defined in some process no worker will be spawned and\nthis means no tasks will be processed. This module is itself defined with several tasks that it will be capable of executing, such as\nStateTransitionTask,\nStateTransitionReductionTask,\nRuntimeProvingTask,\nBlockProvingTask,\nBlockReductionTask,\nBlockBuildingTask,\nNewBlockTask,\nCircuitCompilerTask\nWorkerRegistrationTask.\nWhen the LocalTaskWorkerModule is started it has a subset of start-up tasks, like those above, passed to it.\nThese tasks basically define what sort of computations the worker can handle, as you may want different workers to handle different tasks for resourcing reasons.\nFor example, the majority of the work the AppChain will do is for State Transition related tasks, and so you may want to configure a large share of the workers to handle only the StateTransitionTask\nand StateTransitionReductionTask, which allows easier scalability as only one circuit will be kept in memory. There are two types of tasks: Unprepared, i.e. tasks that donâ€™t have a prepare method and therefore donâ€™t need to wait for registration to get initialized, and\nRegular, i.e. all other tasks that require registration.When the worker is started it first registers the required callback functions for the Unprepared tasks, i.e. CircuitCompilerTask and WorkerRegistrationTask,\nwith its local instance of the queue. Then, the LocalTaskWorkerModule calls the prepare method for non-startup/normal tasks, before registering their callbacks with the queue.\nThis registration ensures the worker is ready to handle any request when one later arrives via the queue. Once all the tasks are registered a promise is resolved, called prepareResolve.\nThis tells the LocalTaskWorkerModule it is ready, and the LocalTaskWorkerModule emits a ready event of its own that other modules like the WorkerReadyModule are waiting for to proceed.","workerreadymodule#WorkerReadyModule":"This is another sequencer module that waits until key events have been emitted by the LocalTaskWorkerModule to signal that the worker\nis ready and that the AppChain can continue. The WorkerReadyModule is called by the AppChain.ts at the end of the start() method.\nIf the waitForReady() method on the WorkerReadyModule is never resolved then the AppChain will never finish its start-up. Note that the\nwaitForReady() will always complete if the AppChain is not a worker, in particular if LocalTaskWorkerModule is not defined.","sequencerstartupmodule#SequencerStartUpModule":"This module is designed to ensure that all zk-circuits are compiled and their verification keys are accessible to the workers that\nwill need them. This spares workers from having to waste resources compiling the circuits themselves. This is achieved by having the AppChain\nuse the verification keys, which are static parameters, as input to the WorkerRegistrationFlow. This in turns leaves\nit as a task on the queue. A worker when starting-up will process the task that has been pushed onto the queue and access these static parameters\nthat way. In order for subsequent workers to have access to the same task, which will be removed from the queue after having been executed, the\nsequencer uses the WorkerRegistrationFlow to push the same task again in a boundless loop. This loop consumes no resources as it is just a Promise that\nawaits until a worker has registered. We ensure it's the new worker that picks up this task from the queue and not an older worker that is already configured,\nby having the old worker be configured to delete the task-handler for the registration from its local queue so that it can't handle that particular kind of task, anymore.","worker-start-up-flow#Worker Start-up Flow":"A summary of the worker registration flow. The sequencer is started and then:\nThe worker registers the callbacks for Unprepared tasks (i.e. those tasks that do not require the worker to be registered first) with the queue, one of which is the\nWorkerRegistration task and the other is CircuitCompilerTask.\nThe AppChain, specifically SequencerStartupModule, emits the CircuitCompilerTask to compile certain zk-circuits of the various zk-Programs.\nThe worker listens to the queue, processes the CircuitCompilerTask task.\nThe SequencerStartupModule invokes  the WorkerRegistrationFlow, which submits a WorkerRegistration task in a boundless\nloop to the queue. Within this task, the verification keys for the circuits are included.\nThe worker listens to the queue, processes the WorkerRegistration task and is initialised.\nThe worker calls the prepare() method for the Regular tasks.\nThe worker registers Regular tasks with the queue.\nThe worker is now able to process all configured tasks emitted to the queue.\nThe AppChain continues and starts submitting tasks, like BlockProving and StateTransition, say, to the queue.","taskqueue#TaskQueue":"The TaskQueue has two different implementations:","bullqueue#BullQueue":"This is Redis underneath. Each worker registers to consume specific jobs. Redis takes care of a lot of the implementation details.\nThis uses a separate Redis instance, whose configuration details are shared with the AppChain  on start-up.\nIn the starter-kit, this is run from Docker.","localtaskqueue#LocalTaskQueue":"This can only be used by one worker built into the AppChain, as it's not really a queue, executing tasks directly where possible.\nThe workNextTasks() is called whenever a task is added to the queue and again after tasks have already been executed (in case any others have been added in the meanwhile).\nThe LocalTaskQueue isn't suitable for production usage because it runs only one instance in-process. But for mock-proofs it's good enough."}},"/docs/tutorials":{"title":"Tutorials","data":{"":"Collection of materials to help you get started with Protokit.","introduction-to-protokit#Introduction to Protokit":"This video workshop goes through the basics of MINA, smart contracts, and Protokit.\nIt walks through building a simple private airdrop application chain."}},"/docs/what-is-protokit":{"title":"What is Protokit?","data":{"":"Protokit is a framework for building privacy enabled application chains (a.k.a. zk-roll-apps / zk-rollups). Enabling developers to build\nzero-knowledge privacy preserving applications with a minimal learning curve.The framework itself is powered by O1JS, an SDK for building zkApps. Thanks to O1JS all applications\nbuilt with Protokit are compatible with the Mina blockchain by design - and can use the Mina L1 for settlement. Therefore tapping into the shared security of the Layer-1 consensus.Furthermore all the code written with Protokit is provable, meaning that transaction execution and block production results in zk-proofs verifiable by the L1 (or anyone).","what-is-a-rollup#What is a rollup?":"Rollups are a form of an L2 scaling solution, originating from popular networks such as Ethereum. L2 solutions\naim to address the scalability issues of L1 networks by moving transactions off-chain, while still maintaining the security guarantees of the L1 network.","optimistic-vs-zk-rollups#Optimistic vs zk-rollups":"There are two main types of rollups, optimistic and zk rollups. Optimistic rollups are the most popular form of rollups, and are used by networks such as Optimism.\nOptimistic rollups rely on fraud proofs to ensure the validity of transactions. Fraud proofs are a mechanism that allows users to challenge invalid transactions.Zk-rollups on the other hand, rely on zero-knowledge proofs to ensure the validity of transactions. Zero-knowledge proofs are a cryptographic mechanism that allows users to prove the validity of a transaction without revealing any information about the transaction itself.\nApplications built with Protokit are zk-rollups, thanks to the underlying O1JS SDK.","what-is-an-application-chain#What is an application chain?":"Application chain is an application specific form of a rollup, unlike a general-purpose rollup like zkSync or Scroll. Application specific rollups allow developers to optimize their rollup implementation\nto suit their application's needs, providing a better user experience (e.g. faster block times) and potentially lower fees than general purpose rollups.","applications-on-mina#Applications on MINA":"","smart-contracts#Smart contracts":"Mina blockchain's L1 is designed with scalability in mind by moving the smart contract transaction execution off-chain.\nSmart contracts are built as zero-knowledge circuits using O1JS, and are executed on the client side (e.g. in the browser). When a block is produced on the Mina blockchain, the block producer\ndoes not have to execute the smart-contract code, but only has to verify the validity of the zero-knowledge proof of the smart contract execution.This approach allows for lower hardware requirements for node operators, and theoretically a higher transaction throughput / scalability. This approach does introduce some\nnovel challenges for developers, where clients transacting in parallel are not aware of each other - thus running into potential race condition scenarios.","rollups#Rollups":"Rollups alleviate the potential race condition scenarios by moving the execution from the client side to the server/sequencer side. Protokit offers a hybrid execution model,\nwhere code can run both on and off chain, thanks to recursive zero-knowledge proofs. This approach allows us to retain the capabilities of smart contracts, while extending them\nwith the capabilities of sequential execution.Mina's smart contracts offer certain built-in primitives for implementing rollups and addressing the inherent race conditions, such as Actions & Reducers.\nHowever the effort to implement and operate a zk-rollup using plain O1JS reducers grows exponentially with the complexity of the application. Protokit aims to abstract away the complexity of building a zk-rollup,\nand allow developers to focus on building their application.\nThanks to Protokit's modular architecture, you'll be soonâ„¢ able to use actions and the underlying sequence state as a mempool for applications built with Protokit.\nQuestion is, where do we draw the line between a smart contract and a rollup?\nProtokit is to rollups, the same as O1JS is to smart contracts - an SDK."}},"/":{"title":"Index","data":{}},"/docs/advanced/protocol":{"title":"Customizing the protocol","data":{"":"Protokit allows for the customization of the underlying protocol.\nThere are multiple ways to do that, we will focus on the easiest and high-levelest approach: Hooks.","hooks#Hooks":"Hooks allow you plug into the protocol and execute certain tasks in pre-defined points in the protocol.Currently, there exist two types of Hooks:\nTransactionHooks\nBlockHooks\nAll Hooks have the important property that they will always be executed, meaning their result doesn't depend on the success of the underlying runtime execution.For example, if you want to implement a hook that implements transaction fees, you want to deduct the fees even though the runtime execution reverts.\nThis is exactly how protocol hooks work, they execute always.\nIn order for your appchain to work properly, make sure that your protocol hooks never fail forcefully and handle all edge cases.\nUnmet o1js assertions like a.assertEquals(b) will lead to your appchain not working properly!","usage#Usage":"In order to use a hook inside your protocol, you simply provide it as a module in your Protocol.","working-with-custom-state#Working with custom state":"Protocol hooks can define their own state and use that to read and modify the appchain state.\nThey work similar to the runtime @state() state and emit StateTransitions under the hood.To define state in ProtocolModules, you will have to use the @protocolState() decorator instead of @state().\nThe rest, like the State and StateMap classes, stays the same.","calling-runtime-modules#Calling runtime modules":"Because of how protokit is architected behind the scenes, ProtocolModules can actually call and use RuntimeModules.Let's assume we have a runtime module called Balances that keeps track of token balances and for every transaction, we want to deduct 100 tokens as a transaction fee.This can be implemented very easily:\nRuntimeModules that are called this was, will be treated as protocol-executed code by the framework.\nThat means that these runtime calls will be executed even if the underlying transaction fails and they cannot use assert.","transactionhooks#TransactionHooks":"Transaction Hooks are classes that extend ProvableTransactionHook.\nThis class forces you to implementpublic onTransaction({ transaction }: BlockProverExecutionData): voidThe provided argument BlockProverExecutionData contains:\ntransaction: The transaction on which this hook was fired\nnetworkState: The network state that was valid during the transaction's execution\nruntimeProof: The proof of the transaction's runtime execution\nstateTransitionProof: The proof of the transaction's state transitions\ntransactionPosition: Indicates whether the transaction was the FIRST or LAST transaction of the block, or if it was somewhere in the MIDDLE\nGiven these possibilities, you can actually consume the result of the runtime execution in your transaction hook.","blockhooks#BlockHooks":"The purpose of block hooks is to mutate and transform the global NetworkState.\nNetworkState is data that is immutable by transactions and is guaranteed to be the same for all transactions in any given block.Between blocks, the BlockHooks are responsible to take the old network state and create the next one that will be provided to all transactions of the coming block.\nExamples of that could be incrementing the block height, providing the last block's state root and others.Block Hooks extend the ProvableBlockHook class and offer two methods:\npublic beforeBlock(blockData: BeforeBlockParameters): NetworkState\npublic afterBlock(blockData: AfterBlockParameters): NetworkState\nThe provided arguments BeforeBlockParameters and AfterBlockParameters both hold:\nstate: BlockProverState;\nnetworkState: The current active networkState, that should be used for transforming","lifecycle#Lifecycle":"Block hooks have two methods that are execute at different points in the block lifecycle.\nafterBlock will be executed after a block is finished.\nbeforeBlock builds on top of the result provided by the afterBlock hook and is execute right before the next block is processed."}},"/docs/advanced/state-proofs":{"title":"Using State Proofs","data":{"":"For some application, it is importants to be able to create a off-chain proof of some state in the protokit state-tree.\nFor example, for privacy-enabled application you want to prove that some data is in the tree,\nbut don't want to reveal under which key this data is stored.You could then attach a nullifier to that proof to prevent double-use.","prerequisites#Prerequisites":"In order to create a state-proof, you need two things:\nThe data\nA witness to that data","fetching-the-data#Fetching the Data":"The data is very simple, you either already have it in your UI or you can fetch it via the query API","fetching-the-witness#Fetching the witness":"After we have the data, we need to prove the relationship between that data and the state-root of the last protokit proof.\nWe do this by fetch the merkle witness and recalculating the state root inside a client-side proof.","creating-the-state-proof#Creating the state proof":"For the state-proof we can then use the data and the witness to recalculate the root hash, which we attach to the publicOutput of our proof.\nInside the protokit runtime, we can then assert that the state-proofs root hash equals to the last state root of the protokit runtime."}},"/docs/architecture":{"title":"Architecture","data":{"":"Protokit is designed to be modular from the ground up, but where does the modularity come from?\nRollups in general have a 3 different layers of modularity: Settlement, Execution and Data Availability.The Protokit framework provides built-in tools for addressing each of these layers, either directly or indirectly (by outsourcing the responsibilities).Protokit's Application chain is composed of the following modularity layers: Runtime, Protocol and Sequencer.\nEvery modularity layer accepts a set of purpose-specific modules implemented in Typescript.\nExisting modules from 3rd party open-source projects can be easily reused too!\nLayer\tResponsibilities\tExample modules\tRuntime\tBusiness logic of the application chain\tBalances, Vesting, Escrow, ...\tProtocol\tUnderlying state machine & block production circuits\tStateTransitionProver, BlockProver, ...\tSequencer\tOrchestrates runtime & protocol, handles the block production pipeline, mempool and more\tPrivateMempool, BlockProducer, GraphQLModule, ...","settlement-execution-and-data-availability#Settlement, execution and data availability":"How does settlement, execution and data availability fit into the architecture of Protokit? The framework primarily takes care of the execution layer of your rollup,\noutsourcing the settlement layer to the Mina L1 blockchain.","data-availability#Data availability":"In the current version of the SDK the data availability layer is handled by the sequencer,\nmaking all Protokit application chains validiums.\nOnce the action/sequence state mempool module becomes available, the data availability will be (optionally) outsourced to the Mina L1 as well.\nAlternatively if you'd like to use a different data availability layer, you could implement your own sequencer module.","rollup-as-a-state-machine#Rollup as a state machine":"Blockchains and especially rollups are simply state machines that describe how a state of a system can transition from state A to state B.\nProtokit is built with this concept in mind, providing a set of tools to make it easy to implement your own rollup as a set of provable state transitions.State in a rollup is represented by a merkle tree of potentially variable height, where each leaf represents a piece of the state itself.\nMerkle trees are then represented by their root hash. Thanks to a combination of merkle trees and zero-knowledge proofs, an app chain can transition from state A to state B in a provable way.Producing a block is equivalent to applying a set of state transitions from state A to state B, where the state transitions are a result of executing user's transactions on the rollup itself.","application-chain#Application chain":"Application chain is a top level modularity container that contains all the components required to run a rollup.To ensure compatibility and ease of development between clients and sequencer(s), an app-chain definition can be reused for both the client(s) and the sequencer.\nLight clients are responsible for forging transactions on the client side, while the sequencer is responsible for e.g. producing blocks after receiving said transactions.\nBoth of these share a portion of the app-chain definition, such as the runtime.As mentioned previously, the app-chain is composed of 3 additional layers ðŸ‘‡"}},"/docs/architecture/runtime":{"title":"Runtime","data":{"":"Runtime is the first modular component of the app-chain, containing all the bussiness logic of the application itself.\nBusiness logic is implemented as runtime modules, defining the runtime state and runtime methods of each module.\nRuntime modules can be composed together to create a runtime that suits the needs of the application.Runtime methods are functions callable by user's transactions, responsible for reading and writing to the state - with accordance to their inner business logic implementation.\nEach runtime module can define it's own state (storage), which can be of two types: state and state map.","runtime-module#Runtime module":"At the time of writing Protokit does not provide any runtime modules out of the box. If your chain needs to work with balances, yo'll have to implement your own runtime module. Alternatively you can\nwait for our upcoming @proto-kit/library package, which will provide a set of runtime modules out of the box.\nExample runtime module \"Balances\" might define its own storage to be a ledger of type state map, storing a key value pairing between public keys and balances.\nAccompanied by methods callable by users via transactions, such as transfer, mint and burn. Transfer method would read the ledger,\ncheck if the sender has enough balance and if so, update the ledger accordingly.Behind the scenes every interaction with the state produces a state transition. Runtime does not apply any state transitions to the merkle tree itself, this allows us to keep the runtime circuits as simple as possible.\nAs a result we can achieve adequate proof paralelisation between business logic and state transition circuits.","soft-failing-runtime-methods#Soft-failing runtime methods":"In order to ensure provability of both successful and failing transactions, we can't fail the proof generation forcefully using built in O1JS assertions (e.g. assertEquals).\nAs an alternative way to soft-fail runtime method execution, we provide a custom assert function that keeps track of the assertion failures and returns them as a part of the runtime method result - as a boolean status.","runtime-module-interoperability#Runtime module interoperability":"Runtime modules within the same runtime are aware of each other, allowing them to call each other's methods and reach each other's state.Calling a method of runtime module B, from within a runtime module A would result in the appropriate state transitions\nwithin each respective module. This allows for a modular approach to building your runtime, where each module can be developed and tested in isolation."}},"/docs/architecture/protocol":{"title":"Protocol","data":{"":"Protocol is the centerpiece of every Protokit app-chain. Firstly it defines how state transitions generated by the rest of the framework are\napplied to the underlying state tree. Secondly it determines how proofs of state transitions are brought together with proofs of runtime execution\nto form a block, or at least a part of it.Every protocol is composed of protocol modules, following the modular design of Protokit. The bare minimum protocol must\nalways contain a StateTransitionProver and a BlockProver module.Although modular, the protocol and sequencer have a certain level of coupling, therefore the need to always specify the state transition and block prover modules.\nThe underlying coupling of the protocol and the sequencer comes from the orchestrational (block production) responsibilities of the sequencer.","state-transitions#State transitions":"One of the core responsibilities of the protocol, is to define how state transitions coming from the rest of the framework are applied to the underlying\nstate tree. State transition is defined by path, from and to properties, where from/to are optional values.This enables state transitions not only to model how a state moves forward, but also to define how a state is meant to look like at a certain point in time.\nThe ability to reason about the current state is reffered to as preconditions. The state transition prover implementation shipped with Protokit, is capable of\nboth enforcing state transition preconditions and state writes.Most importantly, state transition preconditions allow the sequencer to supply unchecked values during on-chain execution of runtime, and still be able to prove the correctness\nof the values supplied within the protocol.Circuits for applying state transitions to the state tree are inifinitely recursive, in order to compensate for the current O1JS circuit size limits. This allows us to apply arbitrary\namount of state transitions per e.g. each runtime method execution.","block-production#Block production":"Blocks are created by either merging a runtime execution proof with a state transition proof, or by merging two block proofs.\nApplying a transaction to a block requires two things: a runtime proof and a state transition proof. Both of these proofs are merged together to generate a 'block proof' within the block prover.\nAs part of this process, both proofs's commitments are cross checked to have proven their computation on top of the same underlying data. This means for instance checking\nif the state transition proof applied all the state transitions emitted by the runtime proof.","extending-the-protocol-with-hooks#Extending the protocol with hooks":"Protocol modules can extend tap into the lifecycle of the existing protocol, by specifying protocol hooks.\nMultiple different protocol hook injection points are available in the protocol out of the box: onTransaction, beforeBlock and afterBlock.The onTransaction hooks have access to the state tree, and can emit state transitions as well. For instance account nonce tracking\nis implemented as an onTransaction hook.\nHooks are executed from within the block prover, and have access to additional protocol context as well. (e.g. which transaction invoked the hook)\nProtocol hooks also allow us to keep track of the last known network state, allowing for an implementation of historical state proofs."}},"/docs/architecture/sequencer":{"title":"Sequencer","data":{"":"Sequencer is the gateway between user's transactions and the block production. In a nutshell, the sequencer is responsible for\naccepting user's transactions into a mempool, validating them, sequencing them as part of the block production process, orchestrating the block production prover worker pipeline,\nand finally submitting the rollup block to the settlement layer.Following the modularity principles, all working components of the sequencer are sequencer modules, and may be added, removed or replaced at developer's convinience.","transaction-sequencing#Transaction sequencing":"One of the main roles of the sequencer node is to execute transactions in a certain predetermined order. Before the sequencer is able to do so, users have to\nsubmit their transactions to the sequencer's compatible mempool - this may be a private mempool, or eventually a public mempool such as the sequence state on the Mina L1.Once the mempool module determines the order of transactions, sequencing can begin. The sequencer will execute all the transactions from the 'block' (bundle) in a simulated fashion, providing updated\nstate from one transaction to another. This allows us to circumvent any potential race conditions steming from client side paralelism, as it may be the case for the Mina L1 smart contracts.Data writes from the sequencing process are persisted in the sequencer's storage, and available as the latest state for the upcoming block, or to be read via external APIs.As part of this process, the sequencer collects all the necessary information for proving, which happens independently from the sequencing. Most importantly the proving itself happens\nin parallel in order to achieve the maximum possible efficiency of the available hardware.","proving-pipeline#Proving pipeline":"Sequencing results in a creation of unproven blocks, which contain all the necessary information extracted during sequencing.\nThis may include transaction execution results, state diffs, the produced state transitions and more.In order for the sequencer to create proofs of all the sequenced computation that happened previously, it has transform the unproven blocks into traces.\nTraces work as an input for our proving pipeline - where all the app-chain circuits can be executed in parallel, since all their inputs/outputs are precomputed as traces.The aforementioned architecture allows us to paralelize the most resource intensive part of the block production process, which is the proving itself.","user-facing-apis#User facing APIs":"Among all other responsibilities, the sequencer may also provide modules for inspecting its internal state via APIs. Out of the box we provide a GraphQL API\nto e.g. read runtime / protocol state, submit transactions to the private mempool or retrieve merkle witnesses for historical state proofs."}},"/docs/faq":{"title":"FAQ","data":{"":"This section gathers the most commonly asked questions about Protokit, and aims to provide a bite-sized answer to each of them.","how-do-smart-contracts-compare-to-runtime-modules#How do smart contracts compare to runtime modules?":"In general purpose blockchains, smart contracts are used to implement business logic. Usually the developer is responsible for\ndeploying a smart contract to the blockchain - normally associated with an on-chain address for the smart-contract itself (like in EVM).With Protokit, the developer is responsible for building their own application chain, which is not a general purpose blockchain, but an application specific\nblockchain. This means that the features of your application are de-facto the features of your own blockchain. Therefore instead of\nimplementing and deploing smart contracts, the developer implements runtime modules and deploys them as a whole as their application chain.","how-does-protokit-enable-privacy#How does Protokit enable privacy?":"Protokit is built on top of MINA's o1js library, which is a zk-dsl. You can use it to write circuits which produce zero knowledge proofs.\nRuntime modules can accept proofs as arguments, which under the hood turns the transaction execution into a recursive zero-knowledge proof.This means you can generate a zero knowledge proof on the client side - e.g. in the browser, and send that proof as part of a transaction to\nyour application chain's runtime. The sequencer will execute your transaction 'on server side', by passing the client side proof to the respective runtime method.","how-is-my-application-chain-connected-to-mina#How is my application chain connected to MINA?":"Application chains built with Protokit can be settled to MINA, this means that the state of your application chain is anchored to MINA's blockchain.\nAll of this is possible thanks to the L1 settlement contract(s), which need to be deployed to MINA's blockchain. These contracts are responsible\nfor verifying the transaction processing and block production of your application chain.\nPlease keep in mind that the L1 contracts are still a work in progress.","do-i-have-to-run-my-own-infrastructure#Do i have to run my own infrastructure?":"As of now, yes. Once your Protokit based application-chain is ready for \"testing\" you will need to run your own infrastructure. This means that you will need to run your own\nsequencer. We are working on making sure hosting your own sequencer is as easy as possible (devops wise).","do-i-have-to-generate-proofs-during-development#Do i have to generate proofs during development?":"No, you do not. It is advised to stick to \"mock proofs\" during development and testing of your application chain. This approach results into quicker iteration\ntimes and faster test suites. If your runtime design is correct and your circuit implementation is sound, then \"enabling proofs\" should be just a matter of sequencer configuration.","what-stage-of-development-is-protokit-in#What stage of development is Protokit in?":"Protokit development began in Q2 2023, and is currently in the early stages of development. We encourage developers to start building with Protokit today, since the 'gist' of the\nSDK is already there. We are working on making the developer experience as smooth as possible, and we are looking forward to your feedback!","how-is-protokit-funded#How is Protokit funded?":"Protokit is funded publicly thanks to the support of community grant programs from the Mina foundation.","is-protokit-free-to-use--opensource#Is Protokit free to use / opensource?":"Yes, and it allways will be.","how-can-i-contribute#How can i contribute?":"The best way to contribute right now is to start building open source runtime modules, and sharing them with the Protokit community.\nWe're working on the Protokit library, if you'd like to see more plug-and-play runtime modules, please consider contributing to the library.","i-am-stuck-where-can-i-get-help#I am stuck, where can i get help?":"You can reach out to #tech-support in our Discord server."}},"/docs/quickstart":{"title":"Quickstart","data":{"":"The fastest way to start building with Protokit is to use the starter kit.\nThe starter kit provides a monorepo aimed at kickstarting application chain development using the Protokit framework.","install-dependencies#Install dependencies":"Before you can start building with Protokit, you need to install the following dependencies:\nNode.js v18\npnpm\nnvm\nAre you using Windows? Please use WSL to run the commands below.","clone-the-starter-kit#Clone the starter kit":"","run-the-tests#Run the tests":"There's an optional --watchAll flag, which will re-run the test suite when files change.Depending on your shell, you may need to prefix any extra flags with an additional --\nlike so: pnpm run test --filter=chain -- --watchAll. This is applicable across all the commands in this guide.","run-the-sequencer--the-ui#Run the sequencer & the UI":"","open-the-demo-ui-in-the-browser#Open the demo UI in the browser":"Open http://localhost:3000 with your browser to see the results. Assuming your setup went well,\nyou'll see an example UI that allows you to interact with your app-chain.Alternatively you can try http://localhost:8080/graphql to interact with the GraphQL API explorer directly.","interact-with-the-demo-ui#Interact with the demo UI":"Setup the Auro wallet if you haven't already. Then connect your wallet in the UI, and claim some tokens from the faucet.Congratulations, you've just ran your first app-chain built using Protokit! ðŸŽ‰","protokit-environments-persistence-and-sequencer-deployment#Protokit environments, persistence and sequencer deployment":"To learn more about Protokit environments and how to host your app-chain, check out the starter-kit readme.","folder-structure#Folder structure":"After completing the quickstart setup, you'll end up with a basic Protokit project.\nThe project itself is a monorepo containing a Next.js/React based web app at apps/web, that connects to an example application chain from packages/chain.The folder structure looks something like this:"}},"/docs/quickstart/app-chain":{"title":"App-chain's runtime","data":{"":"The starter-kit project contains an example application chain, that consists of a runtime created from a single runtime module called Balances.\nThis runtime module stores a ledger of balances for public keys, and the current circulating supply.It also defines a single runtime method called addBalance, which allows tokens to be minted for a certain address. It looks like this:","testing-the-runtime#Testing the runtime":"In general it is considered a good practice to test your runtime modules in isolation. The starter kit\ncomes with a simple test suite that demonstrates how to do this. The test suite below does the following:\nSetup a TestingAppChain.fromRuntime, providing only the Balances module.\nProvides non-mutable configuration for the Balances module, including the totalSupply.\nStarts the application chain, generates keypairs for testing and sets the transaction signer.\nForges a transaction to the Balances module, calling the addBalance method.\nSigns and sends the transaction and produces a block for the application chain.\nQueries the Balances module for the balance of the test account (keypair generated earlier).\nAsserts that the transaction was included in the block, while the execution of the transaction was successful.\nAsserts that the balance of the test account has updated accordingly.\nThe TestingAppChain is a special type of application chain that is designed to be used in tests. It runs an in-memory version of the sequencer as well!","running-the-tests#Running the test(s)":"The test above can be executed with the following command:\nNote: the --watchAll flag is optional, and will re-run the test suite when files change."}},"/docs/quickstart/client-interaction":{"title":"Client interaction","data":{"":"Once you are ready to interact with your app-chain, the first step is to start the sequencer.\nYou may do so by using the Protokit CLI, which is available as part of the starter-kit under the\nfollowing command:\nThe command above will start a local sequencer, which will be available at http://localhost:8080/graphql.","transaction-api#Transaction API":"Every app-chain exposes a transaction API, which is aware of the underlying runtime configuration.\nThis allows us to forge, sign and send transactions to the sequencer without having to worry about\nthe internal workings of the sequencer and its mempool.\nKeep in mind that our \"client app-chain\" is a localhost only app-chain, which means it is\nconfigured to interact with the sequencer running on your local machine.","sending-a-transaction#Sending a transaction":"Previously we've implemented a simple CheckIn runtime module. Let's implement a simple client as\na test suite, that'll interact with our app-chain.The code below does the following:\nGenerate a random signer keypair\nStart the client appChain and register a custom in-memory signer, which will be used to sign transactions\nResolve the GuestBook runtime module, so we can interact with it\nCreate a transaction, which will call the checkIn method of the GuestBook runtime module\nSign and send the transaction to the locally hosted sequencer.\nYou can run the test above with the following command:","query-api#Query API":"The query API allows you to fetch the latest state of the app-chain, using the underlying app-chain module configuration (e.g. available runtime modules).\nLet's query for the latest check-in for a guest, from our GuestBook runtime module.\nThe sequencer only stores the latest known app-chain state, it does not store any historical state.\nHere's a breakdown of what happens in the test suite below:\nSetup the client app-chain and configure a signer\nForge, sign and send a transaction using the transaction API\nWait for a couple seconds for a block to be produced\nQuery the latest check-in for the sender address, from the GraphQL API of the locally hosted sequencer.\nDon't forget to run your test suite again to see the results ðŸ‘†"}},"/docs/quickstart/configuration":{"title":"Configuration","data":{"":"Your app-chain can be configured at three different levels: runtime, chain and client. Firstly we start with the\noverall runtime configuration, specifying the definition/configuration of your runtime module layout:","server--client-configuration#Server & client configuration":"The runtime configuration above is then used to define app-chain configurations for both client and server side app-chains.\nKeep in mind that configuration for the rest of the app-chain, namely the protocol and the sequencer is provided implicitly behind the scenes.\nchain.config.ts is used by Protokit's CLI to start a server-side app-chain, while client.config.ts is used by the Protokit SDK to connect\nto the server-side app-chain via e.g. GraphQL."}},"/docs/quickstart/first-runtime-module":{"title":"Implementing runtime modules","data":{"":"Its safe to assume that you'll want to implement your own runtime module, and add it to the application chain.\nDoing so is very easy, and can be done in a few simple steps. We'll walk through the process of creating a simple\nruntime module called GuestBook.","designing-a-runtime-module#Designing a runtime module":"To design a runtime module, you'll need to consider the following:\nWhat will be configurable in the module?\nWhat data will the module store?\nWhat methods will the module expose?","storage#Storage":"For our GuestBook module, we'll want to allow users to check-in in the guest book.\nWe'll start by defining the data model, namely the CheckIn struct, which will determine what constitutes a check-in.","define-the-runtime-module#Define the runtime module":"Second step is to create our runtime module and define the checkIns storage property, which will map a guest to the check-in they made.","methods#Methods":"Now that we have our storage defined, we can start implementing the methods that will allow users to interact with the module.\nWe'll define the checkIn_ method, which will allow users to check-in in the guest book.\nWe're using the transaction sender to identify and authorize check-ins.","extending-the-app-chain-configuration#Extending the app-chain configuration":"In order to make use of the GuestBook runtime module, we have to add it to the app-chain's runtime configuration.\nCongratulations! You've just implemented a custom runtime module ðŸŽ‰. At this point, you would be\nable to read its storage or send transactions to it from the client side app-chain (e.g. on the UI, or in tests)."}},"/docs/quickstart/user-interface":{"title":"User interface","data":{"":"The starter-kit comes pre-packaged with an example opinionated user interface. It consists of a simple\nNext.js/React application, configured with:\nTailwind CSS for standardised styling\nShadcn UI as a component library\nZustand & Immer as middleware for state management\nDependency on the chain package, which contains your application chain","wallet-compatibility#Wallet compatibility":"The example user interface is compatible with the Auro wallet. This is possible thanks\nto an app-chain level module called the AuroSigner, which delegates the responsibility of signing transactions to the auro wallet.\nConfiguration of the AuroSigner is done implicitly behind the scenes as part of the ClientAppChain in client.config.ts.\nIf you'd like to use a different wallet, you'll have to implement a compatible signer module, following the Signer interface:\nIn automated tests we use a special version of the signer known as the InMemorySigner, that does not require a browser wallet to be installed.","top-level-await#Top-level await":"O1JS uses top-level await, which does not play nicely with Next.js's app router due to the built-in server side rendering.\nHowever there's a simple solution - loading our react components dynamically with ssr disabled.Top-level await incompatibility is the reason for splitting both layout and page into two files, one with a -dynamic suffix and one without.You can learn more about lazy loading react components here.\nCan you think of a better solution to this problem? Let us know!","features#Features":"The example user interface comes with a few features out of the box, with the intention of showcasing various\ninteraction points between the UI and the app-chain. These features are:\nManaging the app-chain client\nConnecting the compatible browser wallet\nPolling for new blocks from the app-chain\nFetching balances for the connected wallet, every time a new block is received\nInteracting with the app-chain's \"faucet\" (Balances.addBalance)\nHandling transaction notifications, by observing transaction statuses in the latest block.","architectural-separation#Architectural separation":"All of the features above are implemented with a clear separation of concerns, by separating the code into three distinct layers:\nData layer (Zustand stores, interaction with the app-chain, data fetching)\nCompositional layer (React containers, connecting the data layer to the presentational layer)\nPresentational layer (React components, responsible for how the data is displayed)","app-chain-client#App-chain client":"Interacting with the locally hosted app-chain from the UI is done through the ClientAppChain, same as in the client interaction documentation. Both the transaction API and the query API is available and preconfigured to work with your app-chain's\nruntime definition.\nKeep in mind that the ClientAppChain uses the GraphQL API of the locally hosted sequencer, so you'll have to\nrun both at the same time.","using-a-different-ui-framework#Using a different UI framework":"If you would like to use a different UI framework/stack than the one provided in the starter-kit, you totally can!\nHowever there's quite a few things you have to keep in mind as far as configuration goes. The current UI setup\nshould give you enough information to switch to a different framework."}},"/docs/reference/module/README":{"title":"@proto-kit/module","data":{"":"@proto-kit/module â€¢ DocsDocumentation / @proto-kit/moduleSet of APIs to define YAB runtime modules and application chains.Application chain consists of multiple runtime modules. Runtime modules can be either implemented as part of the chain directly, or imported from 3rd parties. Here's an example of how a chain with two runtime modules can be defined:\nChain works as a wrapper for all circuit logic contained by the runtime module methods. Compilation produces a wrap circuit including all known methods of the configured runtime modules.Here's an example Balances runtime module:\nThe Balances runtime module shows how the YAB runtime module API can be used:\nruntimeModule() - marks the class as a runtime module\nclass Balance extends RuntimeModule - introduces runtime module APIs into the runtime module\n@state() public totalSupply = State.from<UInt64>(UInt64) - defines a runtime module state of type UInt64, which can be either get or set\n@state() public balances = StateMap.from<PublicKey, UInt64>(PublicKey, UInt64) - defines a runtime module map state, which allows values to be stored under keys, respective of the given key & value types.\npublic constructor(public admin: Admin) - injects a runtime module dependency to another runtime module Admin, which is a standalone runtime module\n@runtimeMethod() public getTotalSupply() - defines a runtime module method containing circuit logic for a runtime state transition. Methods define how the chain state is transformed from the initial state to the resulting state.\nthis.admin.isAdmin() - shows how runtime module interoperability works, a configured runtime module is injected in the constructor, and can be used within the existing methods. Code of the called runtime module becomes part of the original method circuit (setTotalSupply in this case).","method-wrapper-circuit#Method wrapper circuit":"Every runtime module method gets wrapped into an extra outter circuit, which allows the underlying runtime to make assertions about the results of the method execution, such as:\nState transitions\nExecution status\nTransaction hash (method invocation arguments)\nNetwork state (TODO)\nThe good thing is, the YAB runtime module API does this for you automatically, but it pays off to keep this in mind when debugging your runtime modules. Due to the nature of the underlying ZK method lifecycle, methods cannot produce any side effects beyond the state transitions, which are implicitly generated using the State API. Again due to method lifecycle implications, your method code will run multiple times at different stages of its lifecycle, such as:\nCompilation\nSimulation\nProving\nPlease be careful about keeping your runtime module methods side-effect free, since it may introduce inconsistencies in the method lifecycle which may lead to the inability to generate an execution proof.","testing#Testing":"Runtime module methods can be ran or tested in two different modes:\nSimulation\nProving\nSimulation mode means that only the method javascript code will run, and no proving will be done. This is the fastest way of testing your module methods.Provnig mode means that the whole chain needs to be compiled, and then every method execution can be additionally proven by accessing the provers generated during method simulation.Here's an example of how a runtime module method execution proof can be generated, but please keep in mind you also need to enable proofs and compile the chain. More detailed examples can be found in test/modules:"}},"/docs/reference/sdk/README":{"title":"@proto-kit/sdk","data":{"":"@proto-kit/sdk â€¢ DocsDocumentation / @proto-kit/sdkSDK for developing privacy enabled application chains.To use an appchain, you should use the following syntax as provided by this example:\nThe AppChain takes two arguments, a Runtime and a Sequencer.\nThe Runtime holds all modules that have provable code.\nIn a nutshell, all \"smart contract\" logic that a developer wants to create for their rollup.\nFor more documentation on Runtime, please refer to @protokit/module\nThe Sequencer definition.\nA sequencer is responsible for all services that interact with the Runtime, but are not provable code itself.\nThat could be a GraphQL interface, P2P networking layer, database layer, ..."}},"/docs/runtime":{"title":"Runtime","data":{"":"In this section of the documentation we will cover the fundamental concepts behind runtime and runtime modules.\nYou can learn more about the runtime architecture in the architecture docs","designing-runtime-modules#Designing runtime modules":"Runtime modules are fundamentally different than smart-contracts, as in they are not deployed individually,\nbut rather composed into a single Runtime. This means that they don't have individual addresses as contracts do.Therefore when designing e.g. the storage of a runtime module, you must consider the lifetime of the module and the data it stores.\nWith smart-contracts you could deploy a new contract for 'each user' - but you can't do that with a runtime module. Which means you\nhave to mitigate this by storing the data in a way that is shared between all users. The same applies to runtime methods as well.","defining-a-runtime-module#Defining a runtime module":"First step towards building a runtime is to define a runtime module. Typical runtime module will consist of the following:\nconfiguration, storage and methods. Every runtime module must extend the RuntimeModule class, and be decorated\nwith the @runtimeModule() decorator.\nRecord<string, never> signifies an empty configuration object.","configuration#Configuration":"Configuration of the runtime module is immutable during execution. This means that any value you define as configuration,\nwill be made part of the underlying zero knowledge circuits as constants. Config is accessible as part of the\nruntime module instance under this.config.totalSupply."}},"/docs/runtime/composability":{"title":"Composability","data":{"":"Runtime modules can be composed together in two primary ways: inheritance and interoperability.\nThrough inheritance, you can extend the functionality of existing runtime modules with new features.\nOn the other hand, interoperability provides a way to create dependencies between separate runtime modules.","inheritance#Inheritance":"Inheritance provides a simple mechanism for extending the functionality of existing runtime modules.\nIf you'd like to alter the behavior of a runtime module, you can extend it and override its methods.\nYou can even soft disable certain methods if you'd like to prevent them from being called.","interoperability#Interoperability":"Interoperability provides a way to create dependencies between separate runtime modules. Thanks to\nconstructor based dependency injection, you can inject one runtime module into another as a dependency.\nFor this to work, both modules have to be a part of the same runtime.In the example below we inject the Balances runtime module into the Vesting runtime module.\nthis allows us to mint tokens freely, since both modules are part of the same runtime.\nThis is a significant paradigm shift when compared to traditional smart contract development. Its up\nto the developer to determine if multiple modules can safely co-exist within the same runtime. State and method\naccess is permissionless within the same runtime, so you should be careful when injecting dependencies."}},"/docs/runtime/methods":{"title":"Methods","data":{"":"Besides state, runtime modules can also contain methods. In general there are two kinds\nof methods available: runtime methods and non-runtime methods. Non-runtime methods\nare just regular typescript methods, however the runtime methods are in addition decorated by the\n@runtimeMethod() decorator, making them callable by users via transactions.","non-runtime-methods#Non-runtime methods":"Non-runtime methods are especially useful for internal logic that should not be exposed to the user.\nIn order to maintain good testability of the runtime module, it is recommended to keep the general\nmethod implementation without side-effects as well. Methods may freely interact with the state API or other methods,\nand can include a return value too.\nNon-runtime methods that read the state are only executable by the sequencer. You won't be able to call these methods\non the client side (e.g. in the browser or tests), since they would not have access to the required state behind the scenes.","method-visibility#Method visibility":"You can make use of public, private, protected keywords to control the visibility of your methods (or state properties). This becomes\nuseful when you want to control access to methods in the runtime module inheritance chain.","runtime-methods#Runtime methods":"To elevate a method into a runtime method, we must decorate it with the @runtimeMethod() decorator. Runtime methods\nare callable by users via transactions. Where as non-runtime methods are only callable by other methods in the runtime.Keep in mind that runtime methods will be only as secure, as you implement them. The only guarantees that exist within\nruntime methods are the ones you implement yourself. Method visibility has no effect on the @runtimeMethod() decorator,\nthese methods will be callable via transactions regardless of visibility.\nThe example below allows anyone to set a balance for anyone. This is obviously not a good idea, do not do this.","valid-argument-types#Valid argument types":"Runtime methods can only accept arguments of a valid type.âœ… You can use the following data types as runtime method arguments:\nUInt64, UInt32\nField\nSignature\nMerkle witness\nPublicKey and other o1js primitives\nStructs\nðŸ¤¯ Proofs (0-2 proof arguments allowed)\nâŒ The following types are not supported as runtime method arguments:\nnumber\nstring\nobject\narray\nand other non-o1js/native primitives","proofs-as-arguments#Proofs as arguments":"Using proofs as arguments is a powerful feature of the runtime, which results in the provided proof being\nrecursively included in the proof of the runtime method execution. You can generate client-side proofs using o1js's zk-program,\nand pass them as arguments to your runtime methods.\nThe zk program below is a dummy program, it always returns true, effectively proving nothing.\nFor a real use case, make sure to implement a secure and sound zk program that correctly verifies eligibility of the user to mint.\nHere's how an example proof as argument would look like:","assertions#Assertions":"Both regular and runtime methods within the runtime cannot forcefully fail. This means that to handle various\nlogical cases in our runtime logic, we must use soft-failing assertions. The framework exposes an assert(...) method\nto address this issue.We can easily check for various conditions which result in Bool values. And then assert these conditions to be truthy,\nand record an error for the transaction if they're not.You can use as many assertions within your runtime method as you'd like, the overall execution status of the runtime is\na subject to all the assert calls within the method. If one assertion fails, the entire transaction will fail.\nYou cannot use the o1js built in assertion methods, such as assertEquals within your runtime methods. This unfortunately\nrules out usage of primitives that include range checks, or call the built in assertions in any way - such as UInt64 or UInt32.You can use our built in math primitives instead - they are shipped  as @proto-kit/library."}},"/docs/runtime/network-transaction":{"title":"Network & Transaction APIs","data":{"":"Each runtime method has access to the current execution context, which provides access to the following APIs: network and transaction.\nBoth of these allow you to tap into information about the current transaction execution, such as the current block height or the transaction sender.","network-api#Network API":"The network API provides in-runtime method access to the observed network state. Following APIs are available under this.network within\na runtime method:\nCurrent block height\nPrevious block's state root hash","transaction-api#Transaction API":"The transasction API offers access to the information about the transaction which invoked the current runtime method.\nYou can access the following information about the transaction:\nsender\nnonce\nmethodId\nargsHash\nThe methodId and argsHash are used by the runtimeMethod decorator to prove that the runtime method execution was authorized by the transaction sender."}},"/docs/runtime/provable-events":{"title":"Provable Events","data":{"":"The ability for a runtime method to emit provable events gives the user a way to produce events that are verifiable. Use-cases for this include\nthe indexer and processor, and explorers. The events appear in the output of the runtime method and are stored in the database.\nNote that due to the variable-like nature of the number of events emitted, we commit to a hash of the events.Consider the below example for how to define a runtime module and method which outputs provable events.","conditional-events#Conditional events":"Additionally, protokit allows for a conditional emitting of events:"}},"/docs/runtime/state":{"title":"State","data":{"":"Runtime modules are responsible for managing their own state. Runtime state is stored by the sequencer,\nand accessible in a provable way within runtime modules.","state-path#State path":"From an app-chain perspective, there is only a single state tree shared between all runtime modules.\nThis means we need a way to determine which state property belongs to which runtime module to avoid name collisions between modules.We do this by using a state path, which consists of the runtime module name and the state property name. In the case of a state map,\nthe state path is extended with the state key used to access the value.The single state tree model also means that runtime modules can access state from other modules (both read and write). As long as\nthey can reconstruct the module's state paths for each state property.The state API, namely the decorators take care of generating the state paths for you, so you don't have to worry about it.","types-of-state#Types of state":"There are two types of state/storage available for runtime modules: state and state map. State is a single value, while\nstate map is a mapping between two values (key-value). You can have an infinite number of state properties on a module,\nand the state map can have a near indefinite number of key-value pairs.\nAmount of available entries in the state map is a subject to size of the underlying state tree. By default\nthe state tree height is 256, allowing for 2^256 entries combined for the entire app-chain.","allowed-state-types#Allowed state types":"When it comes to determining which data types can be used as state, we have to consider\nboth state values and in the case of a map, also state keys. In fact both of these\nfall under the same constraints.âœ… You can use the following data types as state values and keys:\nUInt64, UInt32 (from @proto-kit/library)\nField\nSignature\nPublicKey and other o1js primitives\nStructs (âš ï¸ Need to be instantiated manually once retrieved from the state API)\nâŒ The following types are not supported as storage values or keys:\nProof(s)","reading-state#Reading state":"Accessing runtime state within a runtime module is done via the state API. State\nis represented as an optional value, since it may or may not exists at the time when its read.\nThis scenario can easily occur, if you're reading a state value before it has been set.","options-and-dummy-values#Options and dummy values":"State values are represented as options, which means there may or may not be a real value underneath. We need options\nin order to execute the runtime method in a provable way, even if there are no state values available. In such case the option\nwill carry a value substitute, known as a dummy value.\nImagine if we tried to execute the runtime method, but we wouldn't be able to provide a value for the retrieved state. Our circuit would\nbehave in an unpredictable way or not work at all.","some-vs-none#Some vs None":"You can determine if the obtained state value exists, or if its a dummy by accessing the .isSome property on the option.","unwrapping-options#Unwrapping options":"Relying on the dummy value is not the best practice, therefore we offer a .orElse(...) method on the option, which\nallows you to provide a fallback value in case the option is none.","structs#Structs":"Structs have to be instantiated manually, since they are not automatically deserialized from the state API. This is due to\nhow o1js's fromFields API behaves - creating a \"non-methods\" version of the struct that just appears to match the struct structure,\nbut does not contain any of its instance methods.\nIn certain cases consuming structs without re-instantiating them will work, but once you override the constructor of the struct you'll\nneed to instantiate the struct by hand yourself.\nHere's an example of how to use structs with the state API:","writing-state#Writing state":"Writing to the state is equally as easy as reading the state. Instead of .get(...) you can use\n.set(...). Setting a value of an already existing state key will overwrite the previous value.\nThe set state API does not work with options, you can pass the actual values you want directly."}},"/docs/runtime/testing":{"title":"Testing","data":{"":"Testing runtime modules allows you to ensure your module works properly, before\nyou plug it into the rest of your app-chain. This section of the documentation\nbuilds on top of the starter kit. (using the jest test runner)","runtime-module#Runtime module":"The example module we will be testing is a simple balances module, which allows\ntokens to be minted at the genesis block. Minting after the genesis block should\nresult in an error.","acceptance-criteria#Acceptance criteria":"The two easiest layers at which the runtime module can be tested are: state and transaction.\nThat means we should use a user signed tranasction, to create a change in the state - or not, depending\non the test scenario.In our case, we can implement two sequential tests:\nâœ… mint at the genesis block\nâŒ mint again in the second block and expect it to fail\nAcceptance criteria for both of these tests will be based on the transaction status,\nand the state of the balances module. Meaning if the user's balance has changed or not.","testing-environment#Testing environment":"The most straightforward way to test your runtime is by wrapping it in an app-chain.\nThis will make your runtime callable by test transactions, and also the underlying runtime data\nfetchable by the query API.You can setup a TestingAppChain by passing your runtime module, setting up the\ntransaction API signer and starting the app-chain like this:\nOnce your testing app-chain is started, you can start writing your actual tests.","test-cases#Test cases":"","-mint-at-the-genesis-block#âœ… Mint at the genesis block":"First test case is to mint at the genesis block, expect the transaction to succeed\nand modify the state of the balances module.Here's what needs to happen for our test case to pass:\nForge and send a transaction to the mintery.mint method\nProduce a block on the testing app-chain\nRetrieve the balance of the transaction sender (alice).\nAssert the transaction status to be truthy, and the balance to be the minted amount.","-mint-again-in-the-second-block-and-expect-it-to-fail#âŒ Mint again in the second block and expect it to fail":"Second test case is to mint at the second block, expect the transaction to fail\nand not modify the state of the balances module.Here's what needs to happen for our test case to pass:\nForge and send a transaction to the mintery.mint method\nProduce the second block on the testing app-chain\nRetrieve the balance of the transaction sender (alice).\nAssert the transaction status to be false, and the balance to be the originally minted amount."}}}